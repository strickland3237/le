@inproceedings{pislar2021should,
  title={When should agents explore?},
  author={Pislar, Miruna and Szepesvari, David and Ostrovski, Georg and Borsa, Diana L and Schaul, Tom},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@book{power1999play,
  title={Play and exploration in children and animals},
  author={Power, Thomas G},
  year={1999},
  publisher={Psychology Press}
}

@article{gershman2018deconstructing,
  title={Deconstructing the human algorithms for exploration},
  author={Gershman, Samuel J},
  journal={Cognition},
  volume={173},
  pages={34--42},
  year={2018},
  publisher={Elsevier}
}

@article{gershman2018dopaminergic,
  title={Dopaminergic genes are associated with both directed and random exploration},
  author={Gershman, Samuel J and Tzovaras, Bastian Greshake},
  journal={Neuropsychologia},
  volume={120},
  pages={97--104},
  year={2018},
  publisher={Elsevier}
}

@article{ebitz2019tonic,
  title={Tonic exploration governs both flexibility and lapses},
  author={Ebitz, R Becket and Sleezer, Brianna J and Jedema, Hank P and Bradberry, Charles W and Hayden, Benjamin Y},
  journal={PLoS computational biology},
  volume={15},
  number={11},
  pages={e1007475},
  year={2019},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{costa2019subcortical,
  title={Subcortical substrates of explore-exploit decisions in primates},
  author={Costa, Vincent D and Mitz, Andrew R and Averbeck, Bruno B},
  journal={Neuron},
  volume={103},
  number={3},
  pages={533--545},
  year={2019},
  publisher={Elsevier}
}

@article{waltz2020differential,
  title={Differential effects of psychotic illness on directed and random exploration},
  author={Waltz, James A and Wilson, Robert C and Albrecht, Matthew A and Frank, Michael J and Gold, James M},
  journal={Computational psychiatry (Cambridge, Mass.)},
  volume={4},
  pages={18},
  year={2020},
  publisher={NIH Public Access}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@inproceedings{dabney2018implicit,
  title={Implicit quantile networks for distributional reinforcement learning},
  author={Dabney, Will and Ostrovski, Georg and Silver, David and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
  pages={1096--1105},
  year={2018},
  organization={PMLR}
}

@article{janner2021offline,
  title={Offline reinforcement learning as one big sequence modeling problem},
  author={Janner, Michael and Li, Qiyang and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={1273--1286},
  year={2021}
}

@inproceedings{kapturowski2018recurrent,
  title={Recurrent experience replay in distributed reinforcement learning},
  author={Kapturowski, Steven and Ostrovski, Georg and Quan, John and Munos, Remi and Dabney, Will},
  booktitle={International conference on learning representations},
  year={2018}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@inproceedings{eberhard2022pink,
  title={Pink noise is all you need: Colored noise exploration in deep reinforcement learning},
  author={Eberhard, Onno and Hollenstein, Jakob and Pinneri, Cristina and Martius, Georg},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{ecoffet2019go,
  title={Go-explore: a new approach for hard-exploration problems},
  author={Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1901.10995},
  year={2019}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@inproceedings{dabney2020temporally,
  title={Temporally-Extended Epsilon-Greedy Exploration},
  author={Dabney, Will and Ostrovski, Georg and Barreto, Andre},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{schaul2019adapting,
  title={Adapting behaviour for learning progress},
  author={Schaul, Tom and Borsa, Diana and Ding, David and Szepesvari, David and Ostrovski, Georg and Dabney, Will and Osindero, Simon},
  journal={arXiv preprint arXiv:1912.06910},
  year={2019}
}

@article{turrigiano2004homeostatic,
  title={Homeostatic plasticity in the developing nervous system},
  author={Turrigiano, Gina G and Nelson, Sacha B},
  journal={Nature reviews neuroscience},
  volume={5},
  number={2},
  pages={97--107},
  year={2004},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{osband2019behaviour,
  title={Behaviour Suite for Reinforcement Learning},
  author={Osband, Ian and Doron, Yotam and Hessel, Matteo and Aslanides, John and Sezener, Eren and Saraiva, Andre and McKinney, Katrina and Lattimore, Tor and Szepesvari, Csaba and Singh, Satinder and others},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{agarwal2022reincarnating,
  title={Reincarnating reinforcement learning: Reusing prior computation to accelerate progress},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={28955--28971},
  year={2022}
}

@article{machado2018revisiting,
  title={Revisiting the arcade learning environment: Evaluation protocols and open problems for general agents},
  author={Machado, Marlos C and Bellemare, Marc G and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={61},
  pages={523--562},
  year={2018}
}

@article{raffin2021stable,
  title={Stable-baselines3: Reliable reinforcement learning implementations},
  author={Raffin, Antonin and Hill, Ashley and Gleave, Adam and Kanervisto, Anssi and Ernestus, Maximilian and Dormann, Noah},
  journal={The Journal of Machine Learning Research},
  volume={22},
  number={1},
  pages={12348--12355},
  year={2021},
  publisher={JMLRORG}
}

@article{pignatelli2023survey,
  title={A Survey of Temporal Credit Assignment in Deep Reinforcement Learning},
  author={Pignatelli, Eduardo and Ferret, Johan and Geist, Matthieu and Mesnard, Thomas and van Hasselt, Hado and Toni, Laura},
  journal={arXiv preprint arXiv:2312.01072},
  year={2023}
}


@article{kumar2022should,
  title={When should we prefer offline reinforcement learning over behavioral cloning?},
  author={Kumar, Aviral and Hong, Joey and Singh, Anikait and Levine, Sergey},
  journal={arXiv preprint arXiv:2204.05618},
  year={2022}
}

@article{gu2022review,
  title={A review of safe reinforcement learning: Methods, theory and applications},
  author={Gu, Shangding and Yang, Long and Du, Yali and Chen, Guang and Walter, Florian and Wang, Jun and Yang, Yaodong and Knoll, Alois},
  journal={arXiv preprint arXiv:2205.10330},
  year={2022}
}

@inproceedings{ravaioli2022safe,
  title={Safe reinforcement learning benchmark environments for aerospace control systems},
  author={Ravaioli, Umberto J and Cunningham, James and McCarroll, John and Gangal, Vardaan and Dunlap, Kyle and Hobbs, Kerianne L},
  booktitle={2022 IEEE Aerospace Conference (AERO)},
  pages={1--20},
  year={2022},
  organization={IEEE}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@article{huan2016sequential,
  title={Sequential Bayesian optimal experimental design via approximate dynamic programming},
  author={Huan, Xun and Marzouk, Youssef M},
  journal={arXiv preprint arXiv:1604.08320},
  year={2016}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={30},
  number={1},
  year={2016}
}

@inproceedings{cobbe2019quantifying,
  title={Quantifying generalization in reinforcement learning},
  author={Cobbe, Karl and Klimov, Oleg and Hesse, Chris and Kim, Taehoon and Schulman, John},
  booktitle={International Conference on Machine Learning},
  pages={1282--1289},
  year={2019},
  organization={PMLR}
}

@inproceedings{cobbe2020leveraging,
  title={Leveraging procedural generation to benchmark reinforcement learning},
  author={Cobbe, Karl and Hesse, Chris and Hilton, Jacob and Schulman, John},
  booktitle={International conference on machine learning},
  pages={2048--2056},
  year={2020},
  organization={PMLR}
}
