@article{gregor2015draw,
  title={DRAW: A recurrent neural network for image generation},
  author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
  journal={arXiv preprint, arXiv:1502.04623},
  year={2015},
  url={https://arxiv.org/pdf/1502.04623.pdf}
}

@article{COMPAS_article, 
title={Machine Bias}, 
url={https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing}, 
journal={ProPublica}, 
author={Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren}, 
year={2016}, 
month={May}}
}

@misc{Reuters_Dastin_2018, 
title={Amazon scraps secret AI recruiting tool that showed bias against women}, 
url={https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G}, 
journal={Reuters}, publisher={Thomson Reuters}, 
author={Dastin, Jeffrey}, 
year={2018}, 
month={Oct}} 

@inproceedings{grgićhlača2018human,
author = {Grgic-Hlaca, Nina and Redmiles, Elissa M. and Gummadi, Krishna P. and Weller, Adrian},
title = {Human Perceptions of Fairness in Algorithmic Decision Making: A Case Study of Criminal Risk Prediction},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186138},
doi = {10.1145/3178876.3186138},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {903–912},
numpages = {10},
location = {Lyon, France},
series = {WWW '18}
}

 @misc{Kohavi, 
 title={Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid}, 
 url={https://aaai.org/papers/kdd96-033-scaling-up-the-accuracy-of-naive-bayes-classifiers-a-decision-tree-hybrid/}, 
 journal={AAAI}, 
 author={Kohavi, Ron}, 
 language={en-US} }


@misc{agarwal2018automated,
      title={Automated Test Generation to Detect Individual Discrimination in AI Models}, 
      author={Aniya Agarwal and Pranay Lohia and Seema Nagar and Kuntal Dey and Diptikalyan Saha},
      year={2018},
      eprint={1809.03260},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{Galhotra2017,
author = {Galhotra, Sainyam and Brun, Yuriy and Meliou, Alexandra},
title = {Fairness Testing: Testing Software for Discrimination},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3106277},
doi = {10.1145/3106237.3106277},
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {498–510},
numpages = {13},
keywords = {fairness testing, testing, software bias, Discrimination testing},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@inproceedings{kusner2018counterfactual, 
title={Counterfactual Fairness}, 
volume={30}, 
url={https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf}, 
booktitle={Advances in Neural Information Processing Systems}, 
publisher={Curran Associates, Inc.}, 
author={Kusner, Matt J and Loftus, Joshua and Russell, Chris and Silva, Ricardo}, 
editor={Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.}, 
year={2017} }

@inproceedings{Dem_parity,
author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
title = {Fairness through Awareness},
year = {2012},
isbn = {9781450311151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090236.2090255},
doi = {10.1145/2090236.2090255},
pages = {214–226},
numpages = {13},
location = {Cambridge, Massachusetts},
series = {ITCS '12}
}

@inproceedings{Equal_opportunity,
 author = {Hardt, Moritz and Price, Eric and Srebro, Nati},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Equality of Opportunity in Supervised Learning},
 url = {https://proceedings.neurips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf},
 volume = {29},
 year = {2016}
}

@INPROCEEDINGS{Fairness_definitions_explained,
  author={Verma, Sahil and Rubin, Julia},
  booktitle={2018 IEEE/ACM International Workshop on Software Fairness (FairWare)}, 
  title={Fairness Definitions Explained}, 
  year={2018},
  volume={},
  number={},
  pages={1-7},
  doi={10.1145/3194770.3194776}}


 @article{Causal_context, 
 title={Causal Context Connects Counterfactual Fairness to Robust Prediction and Group Fairness}, 
 volume={36}, 
 journal={Advances in Neural Information Processing Systems}, 
 author={Anthis, Jacy Reese and Veitch, Victor}, 
 year={2023}, 
 month=dec, 
 pages={}, 
 language={en} }

  @article{Simoiu_Corbett-Davies_Goel_2017, 
  title={The problem of infra-marginality in outcome tests for discrimination}, 
  volume={11}, 
  ISSN={1932-6157, 1941-7330}, 
  DOI={10.1214/17-AOAS1058},
   number={3}, 
   journal={The Annals of Applied Statistics}, 
   publisher={Institute of Mathematical Statistics}, 
   author={Simoiu, Camelia and Corbett-Davies, Sam and Goel, Sharad}, 
   year={2017}, 
   month=sep, 
   pages={1193–1216} }

@inproceedings{Guerdan2023,
author = {Guerdan, Luke and Coston, Amanda and Holstein, Kenneth and Wu, Zhiwei Steven},
title = {Counterfactual Prediction Under Outcome Measurement Error},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3594101},
doi = {10.1145/3593013.3594101},
abstract = {Across domains such as medicine, employment, and criminal justice, predictive models often target labels that imperfectly reflect the outcomes of interest to experts and policymakers. For example, clinical risk assessments deployed to inform physician decision-making often predict measures of healthcare utilization (e.g., costs, hospitalization) as a proxy for patient medical need. These proxies can be subject to outcome measurement error when they systematically differ from the target outcome they are intended to measure. However, prior modeling efforts to characterize and mitigate outcome measurement error overlook the fact that the decision being informed by a model often serves as a risk-mitigating intervention that impacts the target outcome of interest and its recorded proxy. Thus, in these settings, addressing measurement error requires counterfactual modeling of treatment effects on outcomes. In this work, we study intersectional threats to model reliability introduced by outcome measurement error, treatment effects, and selection bias from historical decision-making policies. We develop an unbiased risk minimization method which, given knowledge of proxy measurement error properties, corrects for the combined effects of these challenges. We also develop a method for estimating treatment-dependent measurement error parameters when these are unknown in advance. We demonstrate the utility of our approach theoretically and via experiments on real-world data from randomized controlled trials conducted in healthcare and employment domains. As importantly, we demonstrate that models correcting for outcome measurement error or treatment effects alone suffer from considerable reliability limitations. Our work underscores the importance of considering intersectional threats to model validity during the design and evaluation of predictive models for decision support.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1584–1598},
numpages = {15},
keywords = {validity, model evaluation, causal inference, measurement, algorithmic decision support},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

 @article{Young_Gauci_Scholey_White_Pipingas_2020, 
 title={Self-Selection Bias: An Essential Design Consideration for Nutrition Trials in Healthy Populations}, 
 volume={7}, ISSN={2296-861X}, 
 url={https://www.frontiersin.org/articles/10.3389/fnut.2020.587983}, 
 journal={Frontiers in Nutrition}, 
 author={Young, Lauren M. and Gauci, Sarah and Scholey, Andrew and White, David J. and Pipingas, Andrew}, 
 year={2020} }
