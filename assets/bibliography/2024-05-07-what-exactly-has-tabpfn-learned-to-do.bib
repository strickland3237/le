@inproceedings{
hollmann2023tabpfn,
title={Tab{PFN}: A Transformer That Solves Small Tabular Classification Problems in a Second},
author={Noah Hollmann and Samuel M{\"u}ller and Katharina Eggensperger and Frank Hutter},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=cp5PvcI6w8_}
}

@inproceedings{
muller2022transformers,
title={Transformers Can Do Bayesian Inference},
author={Samuel M{\"u}ller and Noah Hollmann and Sebastian Pineda Arango and Josif Grabocka and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=KSugKcbNf9}
}

@inproceedings{chen2016xgboost,
  title={Xgboost: A scalable tree boosting system},
  author={Chen, Tianqi and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining},
  pages={785--794},
  year={2016}
}

@article{leek2016bladderbatch,
  title={bladderbatch: Bladder gene expression data illustrating batch effects},
  author={Leek, JT},
  journal={R package version},
  volume={1},
  number={0},
  pages={17},
  year={2016}
}

@article{pedregosa2011scikit,
  title={Scikit-learn: Machine learning in Python},
  author={Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  journal={the Journal of machine Learning research},
  volume={12},
  pages={2825--2830},
  year={2011},
  publisher={JMLR. org}
}

@article{mcelfresh2023neural,
  title={When Do Neural Nets Outperform Boosted Trees on Tabular Data?},
  author={McElfresh, Duncan and Khandagale, Sujay and Valverde, Jonathan and Ramakrishnan, Ganesh and Goldblum, Micah and White, Colin and others},
  journal={arXiv preprint arXiv:2305.02997},
  year={2023},
  url={https://openreview.net/pdf?id=CjVdXey4zT}
}

@article{nagler2023statistical,
  title={Statistical Foundations of Prior-Data Fitted Networks},
  author={Nagler, Thomas},
  journal={arXiv preprint arXiv:2305.11097},
  year={2023},
  url={https://proceedings.mlr.press/v202/nagler23a}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{yeo2000new,
  title={A new family of power transformations to improve normality or symmetry},
  author={Yeo, In-Kwon and Johnson, Richard A},
  journal={Biometrika},
  volume={87},
  number={4},
  pages={954--959},
  year={2000},
  publisher={Oxford University Press}
}

@article{bischl2017openml,
  title={Openml benchmarking suites},
  author={Bischl, Bernd and Casalicchio, Giuseppe and Feurer, Matthias and Gijsbers, Pieter and Hutter, Frank and Lang, Michel and Mantovani, Rafael G and van Rijn, Jan N and Vanschoren, Joaquin},
  journal={arXiv preprint arXiv:1708.03731},
  year={2017}
}

@article{lecun1998mnist,
  title={The MNIST database of handwritten digits},
  author={LeCun, Yann},
  journal={http://yann. lecun. com/exdb/mnist/},
  year={1998}
}

@article{krizhevsky2009learning,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={Krizhevsky, Alex},
  year={2009}
}

@book{pearl2009causality,
  title={Causality},
  author={Pearl, Judea},
  year={2009},
  publisher={Cambridge university press}
}

@article{grinsztajn2022tree,
  title={Why do tree-based models still outperform deep learning on typical tabular data?},
  author={Grinsztajn, L{\'e}o and Oyallon, Edouard and Varoquaux, Ga{\"e}l},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={507--520},
  year={2022}
}
